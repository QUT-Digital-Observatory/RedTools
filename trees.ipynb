{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1><strong>&#x1F333; Reddit Trees - constructing conversation trees from posts.</strong></h1>\n",
    "</div> \n",
    "\n",
    "The purpose of this notebook is to guide researchers through the process of assembling conversation trees from Reddit posts. The notebook accepts dataframes as input (refer to Aquisitions notebook) and will output a graph object (which can be saved as a .graphml file) and an adjacency list (which can be saved as a .csv file).\n",
    "\n",
    "Good to Know:\n",
    "\n",
    "&#x2139; The input dataframe needs to include the key columns - link_id, parent_id and replies\n",
    "\n",
    "&#x2139; Graph objects are usually named with a capital G by convention\n",
    "\n",
    "&#x2139; Both graph objects and adjacency lists are portable and can be saved for use in other programes such as Gephi\n",
    "\n",
    "&#x2139; In the graphs produced: nodes = individual comments and submissions, and edges = replies (directed)\n",
    "\n",
    "&#x2139; These are default file names feel free to change them to more meaningful names\n",
    "\n",
    "\n",
    "&#x1F381; Added Bonus:\n",
    "\n",
    "This notebook also includes a workflow to assign a topic to a node based on the text of the post it represents in the graph. There are two options, BERTopic and LDA based topic models. BERTopic requires a GPU for optimal performance while LDA can be run without a GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "from reddit_topic_trees import Reddit_trees\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data to make a working dataframe\n",
    "\n",
    "&#x2713; Check the working dataframe contains the three key columns that the code uses to make the trees - <strong>link_id, parent_id and replies</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data from a csv file\n",
    "\n",
    "data = pd.read_csv('test_data_csv.csv')\n",
    "\n",
    "#check the data\n",
    "\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x1F6D1; You can make some choices about the workflow at this point:\n",
    "\n",
    "you can pass the dataframe unaltered to the graph making code;\n",
    "\n",
    "you can run the BERTopic topic modelling and then make the graphs (requires a GPU for optimal performance);\n",
    "\n",
    "you can run the LDA topic modelling and then make the graphs (requires extra NLP steps).\n",
    "<div style=\"background-color: #90EE90; border: 1px solid #ddd; padding: 10px;\">\n",
    "<strong>&#x2049;</strong> If you are interested in topic models there is a further consideration to be made. Topics are assigned at a document level, that means only one topic will be assigned per document. If you want a more in depth look at the topics being discussed (especially in longer posts) you can choose to expand the documents to a sentence level and model the sentences. However, since we do only want one topic per node this is handled in another notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1><strong>Dataframe by Itself</strong></h1>\n",
    "</div> \n",
    "\n",
    "\n",
    "The first step is to set up the Reddit_trees class which manages the code tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up reddit tree tools class\n",
    "\n",
    "reddit_workflow = Reddit_trees()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the graph making code. It outputs two objects a graph object and an adjacency list dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the graph object and the adjacency list\n",
    "G_tree, adj_list = reddit_workflow.tree_graph_and_adj_list(data, incl_topic = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot a basic plot to see if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a basic graph\n",
    "\n",
    "reddit_workflow.plot_basic_graph(G_tree, 'basic_graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the adjacency list dataframe to see whats in the dataframe as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the adjancey list\n",
    "\n",
    "print(adj_list.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can save the objects for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the graph object\n",
    "\n",
    "reddit_workflow.save_graph(G_tree, 'reddit_tree.graphml')\n",
    "\n",
    "#save the adjacency list\n",
    "\n",
    "reddit_workflow.save_adj_list(adj_list, 'reddit_adj_list.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1><strong>BERTopic topic modelling</strong></h1>\n",
    "</div> \n",
    "\n",
    "https://maartengr.github.io/BERTopic/index.html\n",
    "\n",
    "BERTopic is a topic modeling technique that leverages ðŸ¤— transformers and c-TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
