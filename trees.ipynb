{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"/home/fleetr/RedTools/pics/godcat.png\" alt=\"Godcat\" style=\"width:150px;\"/>\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "    <h1><strong>&#x1F333; Reddit Trees - constructing conversation trees from posts.</strong></h1>\n",
    "</div> \n",
    "\n",
    "The purpose of this notebook is to guide researchers through the process of assembling conversation trees from Reddit posts. The notebook accepts dataframes as input (refer to Aquisitions notebook) and will output a graph object (which can be saved as a .graphml file) and an adjacency list (which can be saved as a .csv file).\n",
    "\n",
    "Good to Know:\n",
    "\n",
    "&#x2139; The input dataframe needs to include the key columns - link_id, parent_id and replies\n",
    "\n",
    "&#x2139; Graph objects are usually named with a capital G by convention\n",
    "\n",
    "&#x2139; Both graph objects and adjacency lists are portable and can be saved for use in other programes such as Gephi\n",
    "\n",
    "&#x2139; In the graphs produced: nodes = individual comments and submissions, and edges = replies (directed)\n",
    "\n",
    "&#x2139; These are default file names feel free to change them to more meaningful names\n",
    "\n",
    "\n",
    "&#x1F381; Added Bonus:\n",
    "\n",
    "This notebook also includes a workflow to assign a topic to a node based on the text of the post it represents in the graph. There are two options, BERTopic and LDA based topic models. BERTopic requires a GPU for optimal performance while LDA can be run without a GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "from reddit_topic_trees import Reddit_trees\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data to make a working dataframe\n",
    "\n",
    "&#x2713; Check the working dataframe contains the three key columns that the code uses to make the trees - <strong>link_id, parent_id and replies</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data from a csv file\n",
    "\n",
    "data = pd.read_csv('test_data_csv.csv')\n",
    "\n",
    "#check the data\n",
    "\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x1F6D1; You can make some choices about the workflow at this point:\n",
    "\n",
    "you can pass the dataframe unaltered to the graph making code;\n",
    "\n",
    "you can run the BERTopic topic modelling and then make the graphs (requires a GPU for optimal performance);\n",
    "\n",
    "you can run the LDA topic modelling and then make the graphs (requires extra NLP steps).\n",
    "<div style=\"background-color: #90EE90; border: 1px solid #ddd; padding: 10px;\">\n",
    "<strong>&#x2049;</strong> If you are interested in topic models there is a further consideration to be made. Topics are assigned at a document level, that means only one topic will be assigned per document. If you want a more in depth look at the topics being discussed (especially in longer posts) you can choose to expand the documents to a sentence level and model the sentences. However, since we do only want one topic per node this is handled in another notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1><strong>Dataframe by Itself</strong></h1>\n",
    "</div> \n",
    "\n",
    "\n",
    "The first step is to set up the Reddit_trees class which manages the code tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up reddit tree tools class\n",
    "\n",
    "reddit_workflow = Reddit_trees()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the graph making code. It outputs two objects a graph object and an adjacency list dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the graph object and the adjacency list\n",
    "G_tree, adj_list = reddit_workflow.tree_graph_and_adj_list(data, incl_topic = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot a basic plot to see if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a basic graph\n",
    "\n",
    "reddit_workflow.plot_basic_graph(G_tree, 'basic_graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the adjacency list dataframe to see whats in the dataframe as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the adjancey list\n",
    "\n",
    "print(adj_list.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can save the objects for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the graph object\n",
    "\n",
    "reddit_workflow.save_graph(G_tree, 'reddit_tree.graphml')\n",
    "\n",
    "#save the adjacency list\n",
    "\n",
    "reddit_workflow.save_adj_list(adj_list, 'reddit_adj_list.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1><strong>BERTopic topic modelling</strong></h1>\n",
    "</div> \n",
    "\n",
    "https://maartengr.github.io/BERTopic/index.html\n",
    "\n",
    "BERTopic is a topic modeling technique that leverages ðŸ¤— transformers and c-TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions.\n",
    "\n",
    "We are going to use the topic model to assign a topic to each of the nodes in our graph. This will provide more information about the topics of discussion going on in the tree representation of the reddit conversations. \n",
    "\n",
    "We can topic model the submissions (i.e. the original post), the comments (i.e. the replies to the orginal post), or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    " \n",
    "submissions  = pd.read_csv('submissions_csv.csv')\n",
    "\n",
    "comments = pd.read_csv('comments_csv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model the comments only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model the comments\n",
    "\n",
    "#this will return a dataframe with the comments plus added columns with the topic and a list of topics\n",
    "\n",
    "comments_df, topic_list = reddit_workflow.topic_model_comments(comments, 'body')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model the submissions only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model the submissions\n",
    "\n",
    "#this will return a dataframe with the submissions plus added columns with the topic and a list of topics\n",
    "\n",
    "submissions_df, topic_list = reddit_workflow.topic_model_submissions(submissions, 'title', 'selftext')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model the submissions and comments\n",
    "\n",
    "#this will return a dataframe with the submissions and comments plus added columns with the topic and a list of topics\n",
    "\n",
    "combined_df, topic_list = reddit_workflow.topic_model_combined(submissions, comments, 'body', 'selftext', 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should pass the combined dataframe for the sake of completeness of the graphs. This way the orginal submission and the commetns are in the same topic space. However the \"incl_topic\" flag needs to be set to True in the function arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_combined, adj_list_combined = reddit_workflow.tree_graph_and_adj_list(combined_df, incl_topic = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check out the adjacency list and finally save the Graph object to a .graphml to explore in a visualisation tool like Gephi.\n",
    "\n",
    "https://gephi.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adj_list_combined.head(10))\n",
    "\n",
    "reddit_workflow.save_graph(G_combined, 'reddit_combined_tree.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1><strong>LDA topic modelling</strong></h1>\n",
    "</div> \n",
    "\n",
    "https://en.m.wikipedia.org/wiki/Latent_Dirichlet_allocation\n",
    "\n",
    "\n",
    "We are going to use the topic model to assign a topic to each of the nodes in our graph. This will provide more information about the topics of discussion going on in the tree representation of the reddit conversations. \n",
    "\n",
    "The major difference is that the LDA method requires you to specifiy the number of topics you want to extract from the text. This can be tricky and there are no magic numbers. You should choose a reasonable number depending on the number of documents in the total corpus. You ma want to experiment.\n",
    "\n",
    "We can topic model the submissions (i.e. the original post), the comments (i.e. the replies to the orginal post), or both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    " \n",
    "submissions  = pd.read_csv('submissions_csv.csv')\n",
    "\n",
    "comments = pd.read_csv('comments_csv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model the comments only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_lda, lda_model_comments = reddit_workflow.lda_comments(comments, 'body', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model the submissions only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_lda, lda_model_submissions = reddit_workflow.lda_submissions(submissions, 'title', 'selftext', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_lda = reddit_workflow.lda_combined(submissions, comments, 'body', 'selftext', 'title', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_combined_lda, adj_list_combined_lda = reddit_workflow.tree_graph_and_adj_list(combined_lda, incl_topic = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check out the adjacency list and finally save the Graph object to a .graphml to explore in a visualisation tool like Gephi.\n",
    "\n",
    "https://gephi.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adj_list_combined_lda.head(10))\n",
    "\n",
    "reddit_workflow.save_graph(G_combined_lda, 'reddit_combined_lda_tree.graphml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
